{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af4c1247",
   "metadata": {},
   "source": [
    "### Distilling DeepSeek Coder 1.3B for the purpose of creating a student model for test case assertion generation\n",
    "\n",
    "First we install and import the needed requirements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c1c1e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in d:\\delft\\anaconda3\\lib\\site-packages (2.7.0+cu118)\n",
      "Requirement already satisfied: torchvision in d:\\delft\\anaconda3\\lib\\site-packages (0.22.0+cu118)\n",
      "Requirement already satisfied: torchaudio in d:\\delft\\anaconda3\\lib\\site-packages (2.7.0+cu118)\n",
      "Requirement already satisfied: filelock in d:\\delft\\anaconda3\\lib\\site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in d:\\delft\\anaconda3\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in d:\\delft\\anaconda3\\lib\\site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in d:\\delft\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in d:\\delft\\anaconda3\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in d:\\delft\\anaconda3\\lib\\site-packages (from torch) (2023.3.0)\n",
      "Requirement already satisfied: numpy in d:\\delft\\anaconda3\\lib\\site-packages (from torchvision) (1.24.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in d:\\delft\\anaconda3\\lib\\site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\delft\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\delft\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "37cd6c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==4.26.1\n",
      "  Obtaining dependency information for transformers==4.26.1 from https://files.pythonhosted.org/packages/1e/e2/60c3f4691b16d126ee9cfe28f598b13c424b60350ab339aba81aef054b8f/transformers-4.26.1-py3-none-any.whl.metadata\n",
      "  Downloading transformers-4.26.1-py3-none-any.whl.metadata (100 kB)\n",
      "     ---------------------------------------- 0.0/100.3 kB ? eta -:--:--\n",
      "     -------------------------------------- 100.3/100.3 kB 5.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: filelock in d:\\delft\\anaconda3\\lib\\site-packages (from transformers==4.26.1) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in d:\\delft\\anaconda3\\lib\\site-packages (from transformers==4.26.1) (0.31.1)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\delft\\anaconda3\\lib\\site-packages (from transformers==4.26.1) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\delft\\anaconda3\\lib\\site-packages (from transformers==4.26.1) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\delft\\anaconda3\\lib\\site-packages (from transformers==4.26.1) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\delft\\anaconda3\\lib\\site-packages (from transformers==4.26.1) (2022.7.9)\n",
      "Requirement already satisfied: requests in d:\\delft\\anaconda3\\lib\\site-packages (from transformers==4.26.1) (2.31.0)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.26.1)\n",
      "  Obtaining dependency information for tokenizers!=0.11.3,<0.14,>=0.11.1 from https://files.pythonhosted.org/packages/62/41/93d3135ec30f596a71490ce11a73572190fe80e85a2aea18f116a520cc41/tokenizers-0.13.3-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading tokenizers-0.13.3-cp311-cp311-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in d:\\delft\\anaconda3\\lib\\site-packages (from transformers==4.26.1) (4.65.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\delft\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.26.1) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\delft\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.26.1) (4.12.2)\n",
      "Requirement already satisfied: colorama in d:\\delft\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers==4.26.1) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\delft\\anaconda3\\lib\\site-packages (from requests->transformers==4.26.1) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\delft\\anaconda3\\lib\\site-packages (from requests->transformers==4.26.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\delft\\anaconda3\\lib\\site-packages (from requests->transformers==4.26.1) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\delft\\anaconda3\\lib\\site-packages (from requests->transformers==4.26.1) (2024.2.2)\n",
      "Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
      "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.3/6.3 MB 6.5 MB/s eta 0:00:01\n",
      "   --- ------------------------------------ 0.6/6.3 MB 6.1 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 0.9/6.3 MB 6.2 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 1.0/6.3 MB 6.6 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 1.0/6.3 MB 6.6 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 1.3/6.3 MB 4.4 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 1.5/6.3 MB 4.8 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 1.9/6.3 MB 4.9 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 2.1/6.3 MB 5.1 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 2.1/6.3 MB 5.1 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 2.1/6.3 MB 5.1 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 2.1/6.3 MB 5.1 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 2.1/6.3 MB 5.1 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 2.1/6.3 MB 5.1 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 2.1/6.3 MB 5.1 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 2.3/6.3 MB 3.1 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 2.6/6.3 MB 3.2 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 2.9/6.3 MB 3.4 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 3.2/6.3 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 3.5/6.3 MB 3.8 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 3.9/6.3 MB 4.0 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 4.2/6.3 MB 4.2 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 4.2/6.3 MB 4.2 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 4.2/6.3 MB 4.2 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 4.2/6.3 MB 4.2 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 4.2/6.3 MB 4.2 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 4.2/6.3 MB 4.2 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 4.2/6.3 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 4.6/6.3 MB 3.4 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 5.0/6.3 MB 3.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 5.2/6.3 MB 3.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 5.6/6.3 MB 3.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 6.0/6.3 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.3/6.3 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.3/6.3 MB 3.9 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.13.3-cp311-cp311-win_amd64.whl (3.5 MB)\n",
      "   ---------------------------------------- 0.0/3.5 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.5/3.5 MB 11.3 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 1.0/3.5 MB 10.2 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 1.2/3.5 MB 8.8 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 1.8/3.5 MB 9.4 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 2.2/3.5 MB 10.0 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 2.7/3.5 MB 9.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 3.1/3.5 MB 9.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  3.5/3.5 MB 9.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.5/3.5 MB 8.9 MB/s eta 0:00:00\n",
      "Installing collected packages: tokenizers, transformers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.21.1\n",
      "    Uninstalling tokenizers-0.21.1:\n",
      "      Successfully uninstalled tokenizers-0.21.1\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.51.3\n",
      "    Uninstalling transformers-4.51.3:\n",
      "      Successfully uninstalled transformers-4.51.3\n",
      "Successfully installed tokenizers-0.13.3 transformers-4.26.1\n"
     ]
    }
   ],
   "source": [
    "!pip3 install transformers==4.26.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d94e99f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing decompression of logits...\n",
      "Entry loaded successfully.\n",
      "\n",
      "Teacher prediction:\n",
      "assertNotNull(ret);\n",
      "assertEquals(Integer.valueOf(3), ret);\n",
      "\n",
      "Reference assertions:\n",
      "assertNotNull(ret);\n",
      "assertEquals(Long.class, ret.getClass());\n",
      "assertEquals(123L, ret);\n",
      "\n",
      "Successfully decompressed logits!\n",
      "Shape: torch.Size([512, 32100])\n",
      "Data type: torch.float32\n",
      "Min value: -12.0625\n",
      "Max value: 39.4688\n",
      "Sample values (first 5): [11.985416412353516, 29.16250228881836, 1.6791677474975586, -1.7562494277954102, -1.7562494277954102]\n",
      "Compression format: quantized_4bit\n",
      "Compression ratio: 59.81x\n",
      "Original size: 31.35 MB\n",
      "Compressed size: 0.52 MB\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import (\n",
    "    T5ForConditionalGeneration,\n",
    "    RobertaTokenizer,\n",
    "    get_linear_schedule_with_warmup\n",
    ")\n",
    "from torch.optim import AdamW\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from Data.student_dataset import StudentDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06df29c",
   "metadata": {},
   "source": [
    "Let's start with understanding the data format. We have the /Data/dataset_with_predictions.jsonl file, containing the data (both input and output) for the teacher model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "783e1a93",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "NUM_LINES_TO_INSPECT = 5\n",
    "DATA_PATH = \"Data/dataset_with_predictions.jsonl\"\n",
    "\n",
    "inspected_data = []\n",
    "\n",
    "with open(DATA_PATH, 'r') as data_file:\n",
    "    for i, line_content in enumerate(data_file):\n",
    "        if i >= NUM_LINES_TO_INSPECT:\n",
    "            break\n",
    "        data = json.loads(line_content.strip())\n",
    "        inspected_data.append(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a216998",
   "metadata": {},
   "source": [
    "Now let's look closer at the parsed JSON entry:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d57a1d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['repository', 'focal_file', 'test_method_original', 'test_method_masked', 'assertions', 'method_under_test', 'teacher_prediction', 'teacher_parsed_assertions', 'teacher_metrics', 'teacher_logits'])\n",
      "@Test\n",
      "    public void testNaturalNumber() throws Exception {\n",
      "        Object ret = reader.read(\"123\");\n",
      "\n",
      "    }\n",
      "['assertNotNull(ret);', 'assertEquals(Long.class, ret.getClass());', 'assertEquals(123L, ret);']\n",
      "assertNotNull(ret);\n",
      "assertEquals(Integer.valueOf(3), ret);\n",
      "['assertNotNull(ret);', 'assertEquals(Integer.valueOf(3), ret);']\n",
      "{'precision': 1.0, 'recall': 0.6666666666666666, 'f1': 0.8, 'accuracy': 0.6666666666666666, 'similarity': 1.0, 'exact_matches': 2, 'generated_count': 2, 'reference_count': 3}\n"
     ]
    }
   ],
   "source": [
    "print(inspected_data[0].keys())\n",
    "print(inspected_data[0][\"test_method_masked\"])\n",
    "print(inspected_data[0][\"assertions\"])\n",
    "print(inspected_data[0][\"teacher_prediction\"])\n",
    "print(inspected_data[0][\"teacher_parsed_assertions\"])\n",
    "print(inspected_data[0][\"teacher_metrics\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328d2868",
   "metadata": {},
   "source": [
    "As we can see, the data contains the repository from which the data is taken, the file that contains the class that is being tested, the test method that was written, as well as a separated version of it (a masked test and the assertions separately), the method from the original class that is being tested, the prediction of the teacher model (both as a string and as a list of assertions), some teacher metrics regarding its prediction performance and the teacher's output logits (which we will use for the loss function of the student model).\n",
    "\n",
    "Now, for every entry from the dataset, we need to construct an input for the student model that follows the same format as the input for the teacher model (as defined in DataGeneration/train_teacher_model.py). We also need to tokenize those inputs. We do this using the StudentDataset class, that will manage and tokenize the student model's input data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c7316d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class StudentDataset(Dataset):\n",
    "# This class was moved to Data/student_dataset for multithreading purposes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10022951",
   "metadata": {},
   "source": [
    "Now that we have the dataset class itself, we will also need a method to load the data that we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b96795ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(jsonl_path, max_samples):\n",
    "    \"\"\"Load data from JSONL file\"\"\"\n",
    "    data = []\n",
    "    counter = 0\n",
    "    with open(jsonl_path, 'r') as f:\n",
    "        for line in f:\n",
    "            if counter >= max_samples: break\n",
    "            if line.strip():\n",
    "                try:\n",
    "                    data.append(json.loads(line))\n",
    "                    counter += 1\n",
    "                except json.JSONDecodeError:\n",
    "                    continue\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140f02a2",
   "metadata": {},
   "source": [
    "We also need a method to train the student model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "197e16a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_student_model(model, tokenizer, train_dataloader, val_dataloader, args):\n",
    "    \"\"\"Train the student model to match the teacher's output on the assertion generation task\"\"\"\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    # Setup tensorboard if available\n",
    "    try:\n",
    "        from torch.utils.tensorboard import SummaryWriter\n",
    "        tensorboard_writer = SummaryWriter(log_dir=os.path.join(args[\"output_dir\"], \"tensorboard\"))\n",
    "        use_tensorboard = True\n",
    "    except ImportError:\n",
    "        use_tensorboard = False\n",
    "\n",
    "    # Prepare optimizer and scheduler\n",
    "    no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_grouped_parameters = [\n",
    "        {\n",
    "            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "            \"weight_decay\": args[\"weight_decay\"],\n",
    "        },\n",
    "        {\n",
    "            \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "            \"weight_decay\": 0.0,\n",
    "        },\n",
    "    ]\n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr=args[\"learning_rate\"])\n",
    "\n",
    "    # Calculate total training steps\n",
    "    if args[\"max_steps\"] > 0:\n",
    "        t_total = args[\"max_steps\"]\n",
    "        num_epochs = args[\"max_steps\"] // (len(train_dataloader) // args[\"gradient_accumulation_steps\"]) + 1\n",
    "    else:\n",
    "        t_total = len(train_dataloader) // args[\"gradient_accumulation_steps\"] * args[\"epochs\"]\n",
    "        num_epochs = args[\"epochs\"]\n",
    "\n",
    "    # Create scheduler\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=args[\"warmup_steps\"],\n",
    "        num_training_steps=t_total\n",
    "    )\n",
    "\n",
    "    # Mixed precision training if requested\n",
    "    scaler = torch.cuda.amp.GradScaler() if args[\"fp16\"] else None\n",
    "\n",
    "    # Track metrics\n",
    "    best_val_loss = float('inf')\n",
    "    global_step = 0\n",
    "    epochs_without_improvement = 0\n",
    "\n",
    "    # For per-batch metrics\n",
    "    batch_loss_window_size = args[\"batch_metrics_window\"]\n",
    "    batch_losses = []\n",
    "    batch_accuracies = []\n",
    "    batch_similarities = []\n",
    "    eval_pool_size = args[\"batch_eval_pool\"]  # Number of examples to evaluate in each batch\n",
    "\n",
    "    # Create output directory\n",
    "    os.makedirs(args[\"output_dir\"], exist_ok=True)\n",
    "\n",
    "    # Save training arguments\n",
    "    with open(os.path.join(args[\"output_dir\"], \"training_args.json\"), \"w\") as f:\n",
    "        json.dump(args, f, indent=4)\n",
    "\n",
    "    # Create metrics file\n",
    "    metrics_file = os.path.join(args[\"output_dir\"], \"training_metrics.csv\")\n",
    "    with open(metrics_file, \"w\") as f:\n",
    "        f.write(\"epoch,batch,global_step,loss,accuracy,similarity,lr,examples_per_second\\n\")\n",
    "\n",
    "    # Main training loop\n",
    "    print(f\"Starting training for {num_epochs} epochs...\")\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "        epoch_start_time = time.time()\n",
    "        examples_processed = 0\n",
    "\n",
    "        progress_bar = tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "\n",
    "        for batch_idx, batch in enumerate(progress_bar):\n",
    "            batch_start_time = time.time()\n",
    "            examples_in_batch = len(batch[\"input_ids\"])\n",
    "            examples_processed += examples_in_batch\n",
    "\n",
    "            # Move batch to device\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            teacher_logits = batch[\"teacher_logits\"].to(device)\n",
    "\n",
    "            # Forward pass with optional mixed precision\n",
    "            if args[\"fp16\"]:\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    outputs = model(\n",
    "                        input_ids=input_ids,\n",
    "                        attention_mask=attention_mask,\n",
    "                        labels=labels\n",
    "                    )\n",
    "                    loss = outputs.loss / args[\"gradient_accumulation_steps\"]\n",
    "                    student_pred_logits = student_outputs.logits\n",
    "                    \n",
    "                    if student_pred_logits.shape[1] != teacher_logits_batch.shape[1]:\n",
    "                        print(\"Student and teacher logits sizes do not match\")\n",
    "                        pass\n",
    "                    \n",
    "                    active_loss_mask = student_labels.view(-1) != -100 # Flattened mask\n",
    "\n",
    "                    active_student_log_probs = torch.nn.functional.log_softmax(\n",
    "                        student_logits.view(-1, student_pred_logits.size(-1))[active_loss_mask] / args[\"distillation_temp\"],\n",
    "                        dim=-1\n",
    "                    )\n",
    "                    active_teacher_probs = torch.nn.functional.softmax(\n",
    "                        teacher_logits.view(-1, teacher_logits_batch.size(-1))[active_loss_mask] / args[\"distillation_temp\"],\n",
    "                        dim=-1\n",
    "                    )\n",
    "\n",
    "                    if active_student_log_probs.numel() > 0:\n",
    "                        loss_fct_kl = torch.nn.KLDivLoss(reduction=\"batchmean\")\n",
    "                        loss_distill = loss_fct_kl(\n",
    "                            active_student_log_probs,\n",
    "                            active_teacher_probs\n",
    "                        ) * (args[\"distillation_temp\"] ** 2) # Scale by T^2\n",
    "                    else:\n",
    "                        loss_distill = torch.tensor(0.0, device=loss_ce.device, dtype=loss_ce.dtype)\n",
    "                        \n",
    "                    loss = args[\"alpha_ce\"] * loss + args[\"alpha_distil\"] * loss_distill\n",
    "\n",
    "                # Backward pass with gradient scaling\n",
    "                scaler.scale(loss).backward()\n",
    "\n",
    "                if (batch_idx + 1) % args[\"gradient_accumulation_steps\"] == 0:\n",
    "                    # Unscales the gradients\n",
    "                    scaler.unscale_(optimizer)\n",
    "\n",
    "                    # Clip gradients\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), args[\"max_grad_norm\"])\n",
    "\n",
    "                    # Update weights\n",
    "                    scaler.step(optimizer)\n",
    "                    scheduler.step()\n",
    "                    scaler.update()\n",
    "                    optimizer.zero_grad()\n",
    "                    global_step += 1\n",
    "            else:\n",
    "                # Standard forward and backward pass\n",
    "                outputs = model(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    labels=labels\n",
    "                )\n",
    "                loss = outputs.loss / args[\"gradient_accumulation_steps\"]\n",
    "                student_pred_logits = student_outputs.logits\n",
    "                    \n",
    "                if student_pred_logits.shape[1] != teacher_logits_batch.shape[1]:\n",
    "                    print(\"Student and teacher logits sizes do not match\")\n",
    "                    pass\n",
    "\n",
    "                active_loss_mask = student_labels.view(-1) != -100 # Flattened mask\n",
    "\n",
    "                active_student_log_probs = torch.nn.functional.log_softmax(\n",
    "                    student_logits.view(-1, student_pred_logits.size(-1))[active_loss_mask] / args[\"distillation_temp\"],\n",
    "                    dim=-1\n",
    "                )\n",
    "                active_teacher_probs = torch.nn.functional.softmax(\n",
    "                    teacher_logits.view(-1, teacher_logits_batch.size(-1))[active_loss_mask] / args[\"distillation_temp\"],\n",
    "                    dim=-1\n",
    "                )\n",
    "\n",
    "                if active_student_log_probs.numel() > 0:\n",
    "                    loss_fct_kl = torch.nn.KLDivLoss(reduction=\"batchmean\")\n",
    "                    loss_distill = loss_fct_kl(\n",
    "                        active_student_log_probs,\n",
    "                        active_teacher_probs\n",
    "                    ) * (args[\"distillation_temp\"] ** 2) # Scale by T^2\n",
    "                else:\n",
    "                    loss_distill = torch.tensor(0.0, device=loss_ce.device, dtype=loss_ce.dtype)\n",
    "                    \n",
    "                loss = args[\"alpha_ce\"] * loss + args[\"alpha_distil\"] * loss_distill\n",
    "\n",
    "                # Backward pass\n",
    "                loss.backward()\n",
    "\n",
    "                if (batch_idx + 1) % args[\"gradient_accumulation_steps\"] == 0:\n",
    "                    # Clip gradients\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), args[\"max_grad_norm\"])\n",
    "\n",
    "                    # Update weights\n",
    "                    optimizer.step()\n",
    "                    scheduler.step()\n",
    "                    optimizer.zero_grad()\n",
    "                    global_step += 1\n",
    "\n",
    "            # Track the loss\n",
    "            loss_value = loss.item() * args[\"gradient_accumulation_steps\"]\n",
    "            epoch_loss += loss_value\n",
    "            batch_losses.append(loss_value)\n",
    "            if len(batch_losses) > batch_loss_window_size:\n",
    "                batch_losses.pop(0)\n",
    "\n",
    "            # Calculate time per example\n",
    "            batch_time = time.time() - batch_start_time\n",
    "            examples_per_second = examples_in_batch / batch_time if batch_time > 0 else 0\n",
    "\n",
    "            # Per-batch metrics: Generate predictions for a few examples to calculate accuracy\n",
    "            if args[\"track_batch_metrics\"] and batch_idx % args[\"batch_metrics_every\"] == 0:\n",
    "                # Sample some examples from batch to evaluate\n",
    "                eval_indices = np.random.choice(\n",
    "                    range(len(input_ids)),\n",
    "                    size=min(eval_pool_size, len(input_ids)),\n",
    "                    replace=False\n",
    "                )\n",
    "\n",
    "                # Switch to eval mode temporarily\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    # Generate predictions for sampled examples\n",
    "                    sampled_input_ids = input_ids[eval_indices]\n",
    "                    sampled_attention_mask = attention_mask[eval_indices]\n",
    "\n",
    "                    generated_ids = model.generate(\n",
    "                        input_ids=sampled_input_ids,\n",
    "                        attention_mask=sampled_attention_mask,\n",
    "                        max_length=args[\"max_tgt_length\"],\n",
    "                        num_beams=4,\n",
    "                        early_stopping=True\n",
    "                    )\n",
    "\n",
    "                    # Calculate accuracy and similarity\n",
    "                    batch_accuracy = 0\n",
    "                    batch_similarity = 0\n",
    "\n",
    "                    for i, idx in enumerate(eval_indices):\n",
    "                        generated_text = tokenizer.decode(generated_ids[i], skip_special_tokens=True)\n",
    "                        reference_text = batch[\"original_target\"][idx]\n",
    "\n",
    "                        try:\n",
    "                            metrics = evaluate_assertions(generated_text, reference_text)\n",
    "                            batch_accuracy += metrics[\"accuracy\"]\n",
    "                            batch_similarity += metrics[\"similarity_score_avg\"]\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error evaluating assertion: {e}\")\n",
    "\n",
    "                    # Average the metrics\n",
    "                    batch_accuracy /= len(eval_indices) if eval_indices else 1\n",
    "                    batch_similarity /= len(eval_indices) if eval_indices else 1\n",
    "\n",
    "                # Switch back to train mode\n",
    "                model.train()\n",
    "\n",
    "                # Track metrics\n",
    "                batch_accuracies.append(batch_accuracy)\n",
    "                batch_similarities.append(batch_similarity)\n",
    "                if len(batch_accuracies) > batch_loss_window_size:\n",
    "                    batch_accuracies.pop(0)\n",
    "                if len(batch_similarities) > batch_loss_window_size:\n",
    "                    batch_similarities.pop(0)\n",
    "\n",
    "                # Calculate moving averages\n",
    "                avg_loss = sum(batch_losses) / len(batch_losses)\n",
    "                avg_accuracy = sum(batch_accuracies) / len(batch_accuracies) if batch_accuracies else 0\n",
    "                avg_similarity = sum(batch_similarities) / len(batch_similarities) if batch_similarities else 0\n",
    "\n",
    "                # Update progress bar\n",
    "                progress_bar.set_postfix({\n",
    "                    \"loss\": avg_loss,\n",
    "                    \"accuracy\": avg_accuracy,\n",
    "                    \"similarity\": avg_similarity,\n",
    "                    \"ex/s\": f\"{examples_per_second:.1f}\"\n",
    "                })\n",
    "\n",
    "                # Log to tensorboard\n",
    "                if use_tensorboard:\n",
    "                    tensorboard_writer.add_scalar(\"batch_loss\", avg_loss, global_step)\n",
    "                    tensorboard_writer.add_scalar(\"batch_accuracy\", avg_accuracy, global_step)\n",
    "                    tensorboard_writer.add_scalar(\"batch_similarity\", avg_similarity, global_step)\n",
    "                    tensorboard_writer.add_scalar(\"lr\", scheduler.get_last_lr()[0], global_step)\n",
    "                    tensorboard_writer.add_scalar(\"examples_per_second\", examples_per_second, global_step)\n",
    "\n",
    "                # Log to CSV\n",
    "                with open(metrics_file, \"a\") as f:\n",
    "                    f.write(\n",
    "                        f\"{epoch + 1},{batch_idx + 1},{global_step},{avg_loss:.6f},{avg_accuracy:.6f},{avg_similarity:.6f},{scheduler.get_last_lr()[0]:.8f},{examples_per_second:.2f}\\n\")\n",
    "            else:\n",
    "                # Just update with loss\n",
    "                avg_loss = sum(batch_losses) / len(batch_losses)\n",
    "                progress_bar.set_postfix({\n",
    "                    \"loss\": avg_loss,\n",
    "                    \"ex/s\": f\"{examples_per_second:.1f}\"\n",
    "                })\n",
    "\n",
    "            # Evaluate periodically\n",
    "            if args[\"eval_steps\"] > 0 and global_step % args[\"eval_steps\"] == 0:\n",
    "                val_loss, eval_results = evaluate_model(model, tokenizer, val_dataloader, device)\n",
    "\n",
    "                # Log to tensorboard\n",
    "                if use_tensorboard:\n",
    "                    tensorboard_writer.add_scalar(\"eval_loss\", val_loss, global_step)\n",
    "                    for metric, value in eval_results.items():\n",
    "                        if isinstance(value, (int, float)):\n",
    "                            tensorboard_writer.add_scalar(f\"eval_{metric}\", value, global_step)\n",
    "\n",
    "                # Print evaluation results\n",
    "                print(f\"\\nEvaluation at step {global_step}:\")\n",
    "                print(f\"  Validation loss: {val_loss:.4f}\")\n",
    "                print(f\"  Similarity score: {eval_results['similarity_score_avg']:.4f}\")\n",
    "                print(f\"  Accuracy: {eval_results['accuracy']:.4f}\")\n",
    "                print(f\"  F1 score: {eval_results['f1']:.4f}\")\n",
    "\n",
    "                # Save best model\n",
    "                if val_loss < best_val_loss:\n",
    "                    best_val_loss = val_loss\n",
    "                    print(f\"  New best validation loss: {val_loss:.4f}\")\n",
    "\n",
    "                    # Save model checkpoint\n",
    "                    model_dir = os.path.join(args[\"output_dir\"], \"best_model\")\n",
    "                    os.makedirs(model_dir, exist_ok=True)\n",
    "                    model.save_pretrained(model_dir)\n",
    "                    tokenizer.save_pretrained(model_dir)\n",
    "\n",
    "                    # Save optimizer and scheduler\n",
    "                    torch.save(optimizer.state_dict(), os.path.join(model_dir, \"optimizer.pt\"))\n",
    "                    torch.save(scheduler.state_dict(), os.path.join(model_dir, \"scheduler.pt\"))\n",
    "\n",
    "                    # Reset patience counter\n",
    "                    epochs_without_improvement = 0\n",
    "                else:\n",
    "                    # Increment patience counter\n",
    "                    epochs_without_improvement += 1\n",
    "\n",
    "                # Early stopping\n",
    "                if 0 < args[\"early_stopping_patience\"] <= epochs_without_improvement:\n",
    "                    print(f\"Early stopping after {epochs_without_improvement} evaluations without improvement\")\n",
    "                    break\n",
    "\n",
    "                # Back to training mode\n",
    "                model.train()\n",
    "\n",
    "            # Save checkpoint\n",
    "            if args[\"save_steps\"] > 0 and global_step % args[\"save_steps\"] == 0:\n",
    "                checkpoint_dir = os.path.join(args[\"output_dir\"], f\"checkpoint-{global_step}\")\n",
    "                os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "                model.save_pretrained(checkpoint_dir)\n",
    "                tokenizer.save_pretrained(checkpoint_dir)\n",
    "\n",
    "                # Save optimizer and scheduler\n",
    "                torch.save(optimizer.state_dict(), os.path.join(checkpoint_dir, \"optimizer.pt\"))\n",
    "                torch.save(scheduler.state_dict(), os.path.join(checkpoint_dir, \"scheduler.pt\"))\n",
    "\n",
    "            # Break if max steps reached\n",
    "            if args[\"max_steps\"] > 0 and global_step >= args[\"max_steps\"]:\n",
    "                break\n",
    "\n",
    "        # Calculate average loss for the epoch\n",
    "        epoch_avg_loss = epoch_loss / len(train_dataloader)\n",
    "        train_losses.append(epoch_avg_loss)\n",
    "\n",
    "        # Calculate epoch time and speed\n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "        examples_per_second = examples_processed / epoch_time if epoch_time > 0 else 0\n",
    "\n",
    "        print(f\"\\nEpoch {epoch + 1}/{num_epochs} completed in {epoch_time:.2f}s ({examples_per_second:.2f} examples/s)\")\n",
    "        print(f\"  Average training loss: {epoch_avg_loss:.4f}\")\n",
    "\n",
    "        # Evaluate at the end of each epoch\n",
    "        print(f\"  Evaluating epoch {epoch + 1}...\")\n",
    "        val_loss, eval_results = evaluate_model(model, tokenizer, val_dataloader, device)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        # Log to tensorboard\n",
    "        if use_tensorboard:\n",
    "            tensorboard_writer.add_scalar(\"epoch_train_loss\", epoch_avg_loss, epoch + 1)\n",
    "            tensorboard_writer.add_scalar(\"epoch_val_loss\", val_loss, epoch + 1)\n",
    "            for metric, value in eval_results.items():\n",
    "                if isinstance(value, (int, float)):\n",
    "                    tensorboard_writer.add_scalar(f\"epoch_eval_{metric}\", value, epoch + 1)\n",
    "\n",
    "        # Print evaluation results\n",
    "        print(f\"  Validation loss: {val_loss:.4f}\")\n",
    "        print(f\"  Similarity score: {eval_results['similarity_score_avg']:.4f}\")\n",
    "        print(f\"  Accuracy: {eval_results['accuracy']:.4f}\")\n",
    "        print(f\"  F1 score: {eval_results['f1']:.4f}\")\n",
    "\n",
    "        # Save best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            print(f\"  New best validation loss: {val_loss:.4f}\")\n",
    "\n",
    "            # Save model checkpoint\n",
    "            model_dir = os.path.join(args[\"output_dir\"], \"best_model\")\n",
    "            os.makedirs(model_dir, exist_ok=True)\n",
    "            model.save_pretrained(model_dir)\n",
    "            tokenizer.save_pretrained(model_dir)\n",
    "\n",
    "            # Reset patience counter\n",
    "            epochs_without_improvement = 0\n",
    "        else:\n",
    "            # Increment patience counter\n",
    "            epochs_without_improvement += 1\n",
    "\n",
    "        # Early stopping\n",
    "        if 0 < args[\"early_stopping_patience\"] <= epochs_without_improvement:\n",
    "            print(f\"Early stopping after {epochs_without_improvement} epochs without improvement\")\n",
    "            break\n",
    "\n",
    "    # Save final model\n",
    "    final_model_dir = os.path.join(args[\"output_dir\"], \"final_model\")\n",
    "    os.makedirs(final_model_dir, exist_ok=True)\n",
    "    model.save_pretrained(final_model_dir)\n",
    "    tokenizer.save_pretrained(final_model_dir)\n",
    "\n",
    "    # Close tensorboard writer\n",
    "    if use_tensorboard:\n",
    "        tensorboard_writer.close()\n",
    "\n",
    "    # Plot loss curves\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, len(train_losses) + 1), train_losses, label='Training Loss')\n",
    "    plt.plot(range(1, len(val_losses) + 1), val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(args[\"output_dir\"], \"loss_curves.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    return model, tokenizer, best_val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ccaa13",
   "metadata": {},
   "source": [
    "Now we will also need to run the training of our student model. For this, we will need to define the training configuration and a method to run the training with that configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3a4aa0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    # --- Data Args ---\n",
    "    \"data_path\": \"Data/dataset_with_predictions.jsonl\",\n",
    "    \"output_dir\": \"./student_model_output\",\n",
    "    \"model_name\": \"Salesforce/codet5-small\",\n",
    "    \"validation_split\": 0.1,\n",
    "    \"max_src_length\": 1024,\n",
    "    \"max_tgt_length\": 512,\n",
    "\n",
    "    # --- Distillation Args ---\n",
    "    \"distillation_temp\": 2.0,\n",
    "    \"alpha_ce\": 0.0,            # Weight for student's own Cross-Entropy loss\n",
    "    \"alpha_distil\": 1.0,        # Weight for distillation loss (e.g., KL divergence)\n",
    "\n",
    "    # --- Training Args ---\n",
    "    \"epochs\": 3,\n",
    "    \"batch_size\": 8,\n",
    "    \"eval_batch_size\": 16,\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"learning_rate\": 5e-5,\n",
    "    \"weight_decay\": 0.01,\n",
    "    \"warmup_steps\": 0,\n",
    "    \"max_grad_norm\": 1.0,\n",
    "    \"max_steps\": -1,\n",
    "    \"fp16\": True,\n",
    "    \"seed\": 42,\n",
    "\n",
    "    # --- Batch Metrics Args (Optional, can simplify by removing) ---\n",
    "    \"track_batch_metrics\": False,\n",
    "    \"batch_metrics_every\": 50,\n",
    "    \"batch_metrics_window\": 50,\n",
    "    \"batch_eval_pool\": 4,\n",
    "\n",
    "    # --- Logging and Saving Args ---\n",
    "    \"logging_steps\": 100,\n",
    "    \"eval_strategy\": \"epoch\",\n",
    "    \"eval_steps\": 500,\n",
    "    \"save_strategy\": \"epoch\",\n",
    "    \"save_steps\": 1000,\n",
    "    \"save_total_limit\": 2,\n",
    "    \"early_stopping_patience\": 3,\n",
    "    \"num_workers\": 2,           \n",
    "    \"max_samples\": 100,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "328a9709",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_student_training(args):\n",
    "    # Set random seed\n",
    "    torch.manual_seed(args[\"seed\"])\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(args[\"seed\"])\n",
    "\n",
    "    # Load dataset\n",
    "    print(f\"Loading dataset from {args['data_path']}...\")\n",
    "    if args[\"max_samples\"] is not None:\n",
    "        data = load_dataset(args[\"data_path\"], args[\"max_samples\"])\n",
    "        print(f\"Using first {len(data)} examples\")\n",
    "    else:\n",
    "        data = load_dataset(args[\"data_path\"])\n",
    "        print(f\"Loaded {len(data)} examples\")\n",
    "\n",
    "    # Split into train and validation sets\n",
    "    train_data, val_data = train_test_split(data, test_size=args[\"validation_split\"], random_state=args[\"seed\"])\n",
    "    print(f\"Training on {len(train_data)} examples, validating on {len(val_data)} examples\")\n",
    "\n",
    "    # Load tokenizer and model\n",
    "    print(f\"Loading model: {args['model_name']}\")\n",
    "    tokenizer = RobertaTokenizer.from_pretrained(args[\"model_name\"])\n",
    "    model = T5ForConditionalGeneration.from_pretrained(args[\"model_name\"])\n",
    "\n",
    "    # Create datasets\n",
    "    train_dataset = StudentDataset(\n",
    "        train_data,\n",
    "        tokenizer,\n",
    "        max_src_length=args[\"max_src_length\"],\n",
    "        max_tgt_length=args[\"max_tgt_length\"]\n",
    "    )\n",
    "    val_dataset = StudentDataset(\n",
    "        val_data,\n",
    "        tokenizer,\n",
    "        max_src_length=args[\"max_src_length\"],\n",
    "        max_tgt_length=args[\"max_tgt_length\"]\n",
    "    )\n",
    "\n",
    "    # Create dataloaders\n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=args[\"batch_size\"],\n",
    "        shuffle=True,\n",
    "        num_workers=args[\"num_workers\"],\n",
    "        pin_memory=True\n",
    "    )\n",
    "    val_dataloader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=args[\"eval_batch_size\"],\n",
    "        shuffle=False,\n",
    "        num_workers=args[\"num_workers\"],\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    # Check for CUDA\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Train model\n",
    "    model, tokenizer, best_val_loss = train_student_model(\n",
    "        model,\n",
    "        tokenizer,\n",
    "        train_dataloader,\n",
    "        val_dataloader,\n",
    "        args\n",
    "    )\n",
    "\n",
    "    print(f\"Training completed! Best validation loss: {best_val_loss:.4f}\")\n",
    "    print(f\"Trained model and checkpoints saved to {args['output_dir']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44c7c246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from Data/dataset_with_predictions.jsonl...\n",
      "Using first 100 examples\n",
      "Training on 90 examples, validating on 10 examples\n",
      "Loading model: Salesforce/codet5-small\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Delft\\Anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_5480\\2635291341.py:45: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler() if args[\"fp16\"] else None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training for 3 epochs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3:   0%|                                                                        | 0/12 [00:00<?, ?it/s]C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_5480\\2635291341.py:97: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Epoch 1/3:   0%|                                                                        | 0/12 [00:27<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 252.00 MiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 8.18 GiB is allocated by PyTorch, and 58.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m run_student_training(config)\n",
      "Cell \u001b[1;32mIn[9], line 60\u001b[0m, in \u001b[0;36mrun_student_training\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing device: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m model, tokenizer, best_val_loss \u001b[38;5;241m=\u001b[39m train_student_model(\n\u001b[0;32m     61\u001b[0m     model,\n\u001b[0;32m     62\u001b[0m     tokenizer,\n\u001b[0;32m     63\u001b[0m     train_dataloader,\n\u001b[0;32m     64\u001b[0m     val_dataloader,\n\u001b[0;32m     65\u001b[0m     args\n\u001b[0;32m     66\u001b[0m )\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining completed! Best validation loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_val_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrained model and checkpoints saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_dir\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[7], line 98\u001b[0m, in \u001b[0;36mtrain_student_model\u001b[1;34m(model, tokenizer, train_dataloader, val_dataloader, args)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfp16\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mamp\u001b[38;5;241m.\u001b[39mautocast():\n\u001b[1;32m---> 98\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m model(\n\u001b[0;32m     99\u001b[0m             input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m    100\u001b[0m             attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m    101\u001b[0m             labels\u001b[38;5;241m=\u001b[39mlabels\n\u001b[0;32m    102\u001b[0m         )\n\u001b[0;32m    103\u001b[0m         loss \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;241m/\u001b[39m args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgradient_accumulation_steps\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    104\u001b[0m         student_pred_logits \u001b[38;5;241m=\u001b[39m student_outputs\u001b[38;5;241m.\u001b[39mlogits\n",
      "File \u001b[1;32mD:\\Delft\\Anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\Delft\\Anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mD:\\Delft\\Anaconda3\\Lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:1696\u001b[0m, in \u001b[0;36mT5ForConditionalGeneration.forward\u001b[1;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1694\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1695\u001b[0m     loss_fct \u001b[38;5;241m=\u001b[39m CrossEntropyLoss(ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m-> 1696\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fct(lm_logits\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, lm_logits\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)), labels\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m   1697\u001b[0m     \u001b[38;5;66;03m# TODO(thom): Add z_loss https://github.com/tensorflow/mesh/blob/fa19d69eafc9a482aff0b59ddd96b025c0cb207d/mesh_tensorflow/layers.py#L666\u001b[39;00m\n\u001b[0;32m   1699\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict:\n",
      "File \u001b[1;32mD:\\Delft\\Anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\Delft\\Anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mD:\\Delft\\Anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:1297\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1296\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m-> 1297\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mcross_entropy(\n\u001b[0;32m   1298\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   1299\u001b[0m         target,\n\u001b[0;32m   1300\u001b[0m         weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight,\n\u001b[0;32m   1301\u001b[0m         ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mignore_index,\n\u001b[0;32m   1302\u001b[0m         reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduction,\n\u001b[0;32m   1303\u001b[0m         label_smoothing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_smoothing,\n\u001b[0;32m   1304\u001b[0m     )\n",
      "File \u001b[1;32mD:\\Delft\\Anaconda3\\Lib\\site-packages\\torch\\nn\\functional.py:3494\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3492\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3493\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3494\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39mcross_entropy_loss(\n\u001b[0;32m   3495\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   3496\u001b[0m     target,\n\u001b[0;32m   3497\u001b[0m     weight,\n\u001b[0;32m   3498\u001b[0m     _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction),\n\u001b[0;32m   3499\u001b[0m     ignore_index,\n\u001b[0;32m   3500\u001b[0m     label_smoothing,\n\u001b[0;32m   3501\u001b[0m )\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 252.00 MiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 8.18 GiB is allocated by PyTorch, and 58.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "run_student_training(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5028f9f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
